{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/mrcnn/model.py:554: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/mrcnn/utils.py:200: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/mrcnn/model.py:601: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    }
   ],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /Users/amankishore/Documents/GitHub/Mask_RCNN/samples/logs/shapes20191001T1342/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1635s 16s/step - loss: 1.6882 - rpn_class_loss: 0.0272 - rpn_bbox_loss: 0.4960 - mrcnn_class_loss: 0.3366 - mrcnn_bbox_loss: 0.3922 - mrcnn_mask_loss: 0.4360 - val_loss: 1.2484 - val_rpn_class_loss: 0.0142 - val_rpn_bbox_loss: 0.4339 - val_mrcnn_class_loss: 0.1785 - val_mrcnn_bbox_loss: 0.2757 - val_mrcnn_mask_loss: 0.3462\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 1. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /Users/amankishore/Documents/GitHub/Mask_RCNN/samples/logs/shapes20191001T1342/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " 39/100 [==========>...................] - ETA: 15:30 - loss: 0.8910 - rpn_class_loss: 0.0177 - rpn_bbox_loss: 0.4346 - mrcnn_class_loss: 0.1030 - mrcnn_bbox_loss: 0.1517 - mrcnn_mask_loss: 0.1841"
     ]
    }
   ],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "# model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "# model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
